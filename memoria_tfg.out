\BOOKMARK [-1][-]{part.1}{I Introducci\363n}{}% 1
\BOOKMARK [0][-]{chapter.1}{Introducci\363n y visi\363n general}{part.1}% 2
\BOOKMARK [1][-]{section.1.1}{Motivaci\363n y justificaci\363n}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.2}{Objetivo}{chapter.1}% 4
\BOOKMARK [-1][-]{part.2}{II Desarrollo}{}% 5
\BOOKMARK [0][-]{chapter.2}{Herramientas utilizadas}{part.2}% 6
\BOOKMARK [1][-]{section.2.1}{Robotic Operating System}{chapter.2}% 7
\BOOKMARK [2][-]{subsection.2.1.1}{Arquitectura de la comunicaci\363n mediante ROS}{section.2.1}% 8
\BOOKMARK [2][-]{subsection.2.1.2}{\277Por qu\351 ROS?}{section.2.1}% 9
\BOOKMARK [1][-]{section.2.2}{Mapas de ocupaci\363n}{chapter.2}% 10
\BOOKMARK [1][-]{section.2.3}{Sensores RGBD}{chapter.2}% 11
\BOOKMARK [2][-]{subsection.2.3.1}{Imagen de profundidad}{section.2.3}% 12
\BOOKMARK [1][-]{section.2.4}{Nubes de puntos}{chapter.2}% 13
\BOOKMARK [1][-]{section.2.5}{You only look once}{chapter.2}% 14
\BOOKMARK [2][-]{subsection.2.5.1}{Compute Unified Device Architecture}{section.2.5}% 15
\BOOKMARK [0][-]{chapter.3}{Dise\361o e implementaci\363n}{part.2}% 16
\BOOKMARK [1][-]{section.3.1}{Vista general del sistema}{chapter.3}% 17
\BOOKMARK [1][-]{section.3.2}{Fuente de datos}{chapter.3}% 18
\BOOKMARK [2][-]{subsection.3.2.1}{Adaptaci\363n del rosbag}{section.3.2}% 19
\BOOKMARK [2][-]{subsection.3.2.2}{Otras fuentes tomadas en cuenta}{section.3.2}% 20
\BOOKMARK [1][-]{section.3.3}{De imagen de profundidad a barrido l\341ser}{chapter.3}% 21
\BOOKMARK [1][-]{section.3.4}{Generaci\363n del mapa de ocupaci\363n}{chapter.3}% 22
\BOOKMARK [1][-]{section.3.5}{Detecci\363n de objetos}{chapter.3}% 23
\BOOKMARK [2][-]{subsection.3.5.1}{Descompresi\363n de la imagen de color}{section.3.5}% 24
\BOOKMARK [2][-]{subsection.3.5.2}{Ejecuci\363n de YOLO}{section.3.5}% 25
\BOOKMARK [1][-]{section.3.6}{Procesamiento de los objetos detectados}{chapter.3}% 26
